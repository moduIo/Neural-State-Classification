{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, MaxPooling1D, Flatten, Embedding, Input\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorboard.plugins.pr_curve import summary as pr_summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../datasets/heli_uniform/heli_1m_uniform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(grid=False, figsize=(15,40), layout=(10,3), bins=100, sharex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is imbalanced with more positive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "(num_samples, num_features) = X.shape\n",
    "print (num_samples, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays Precision-Recall curve for Keras models.\n",
    "\n",
    "Adapted from: https://medium.com/@akionakas/precision-recall-curve-with-keras-cd92647685e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PRTensorBoard(TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # One extra argument to indicate whether or not to use the PR curve summary.\n",
    "        self.pr_curve = kwargs.pop('pr_curve', True)\n",
    "        super(PRTensorBoard, self).__init__(*args, **kwargs)\n",
    "\n",
    "        global tf\n",
    "        import tensorflow as tf\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super(PRTensorBoard, self).set_model(model)\n",
    "\n",
    "        if self.pr_curve:\n",
    "            # Get the prediction and label tensor placeholders.\n",
    "            predictions = self.model._feed_outputs[0]\n",
    "            labels = tf.cast(self.model._feed_targets[0], tf.bool)\n",
    "            # Create the PR summary OP.\n",
    "            self.pr_summary = pr_summary.op(name='pr_curve',\n",
    "                                            predictions=predictions,\n",
    "                                            labels=labels,\n",
    "                                            display_name='Precision-Recall Curve')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super(PRTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "        if self.pr_curve and self.validation_data:\n",
    "            # Get the tensors again.\n",
    "            tensors = self.model._feed_targets + self.model._feed_outputs\n",
    "            # Predict the output.\n",
    "            predictions = self.model.predict(self.validation_data[0])\n",
    "            # Build the dictionary mapping the tensor to the data.\n",
    "            val_data = [self.validation_data[1], predictions]\n",
    "            feed_dict = dict(zip(tensors, val_data))\n",
    "            # Run and add summary.\n",
    "            result = self.sess.run([self.pr_summary], feed_dict=feed_dict)\n",
    "            self.writer.add_summary(result[0], epoch)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(num_features,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print model.metrics_names\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.expand_dims(X_train.as_matrix(), axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test.as_matrix(), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 3x1 convolutions\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "conv1 = Conv1D(16, 3, padding='same', strides=1)(inputs)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "relu1 = Activation('relu')(bn1)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv2 = Conv1D(32, 3, padding='same', strides=1)(relu1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "relu2 = Activation('relu')(bn2)\n",
    "flatten = Flatten()(relu2)\n",
    "\n",
    "# FC 2048\n",
    "fc1 = Dense(2048)(flatten)\n",
    "bn3 = BatchNormalization()(fc1)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "drop1 = Dropout(0.5)(relu3)\n",
    "\n",
    "# FC 1024\n",
    "fc2 = Dense(1024)(drop1)\n",
    "bn4 = BatchNormalization()(fc2)\n",
    "relu4 = Activation('relu')(bn4)\n",
    "drop2 = Dropout(0.5)(relu4)\n",
    "\n",
    "# FC 512\n",
    "fc3 = Dense(512)(drop2)\n",
    "bn5 = BatchNormalization()(fc3)\n",
    "relu5 = Activation('relu')(bn5)\n",
    "drop3 = Dropout(0.5)(relu5)\n",
    "\n",
    "# Output\n",
    "fc4 = Dense(1)(drop3)\n",
    "outputs = Activation('sigmoid')(fc4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/10\n",
      "800000/800000 [==============================] - 3035s 4ms/step - loss: 0.2693 - acc: 0.8831 - val_loss: 0.1730 - val_acc: 0.9271\n",
      "Epoch 2/10\n",
      "800000/800000 [==============================] - 2778s 3ms/step - loss: 0.2015 - acc: 0.9136 - val_loss: 0.1461 - val_acc: 0.9368\n",
      "Epoch 3/10\n",
      "800000/800000 [==============================] - 2749s 3ms/step - loss: 0.1809 - acc: 0.9235 - val_loss: 0.1292 - val_acc: 0.9473\n",
      "Epoch 4/10\n",
      "800000/800000 [==============================] - 2760s 3ms/step - loss: 0.1667 - acc: 0.9297 - val_loss: 0.1212 - val_acc: 0.9511\n",
      "Epoch 5/10\n",
      "800000/800000 [==============================] - 2758s 3ms/step - loss: 0.1568 - acc: 0.9341 - val_loss: 0.1202 - val_acc: 0.9496\n",
      "Epoch 6/10\n",
      "800000/800000 [==============================] - 2800s 3ms/step - loss: 0.1496 - acc: 0.9372 - val_loss: 0.1096 - val_acc: 0.9545\n",
      "Epoch 7/10\n",
      "800000/800000 [==============================] - 2804s 4ms/step - loss: 0.1431 - acc: 0.9399 - val_loss: 0.1050 - val_acc: 0.9574\n",
      "Epoch 8/10\n",
      "800000/800000 [==============================] - 2794s 3ms/step - loss: 0.1386 - acc: 0.9422 - val_loss: 0.1110 - val_acc: 0.9533\n",
      "Epoch 9/10\n",
      "800000/800000 [==============================] - 2809s 4ms/step - loss: 0.1343 - acc: 0.9444 - val_loss: 0.1010 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      "800000/800000 [==============================] - 2815s 4ms/step - loss: 0.1297 - acc: 0.9463 - val_loss: 0.1099 - val_acc: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x142639990>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_cnn, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[X_test_cnn, y_test],\n",
    "          shuffle=True,\n",
    "          callbacks=[PRTensorBoard(log_dir='logs/nadam'), EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test_cnn, y_test, batch_size=batch_size)\n",
    "print model.metrics_names\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('models/cnn_16_32_dropout25_nadam.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
