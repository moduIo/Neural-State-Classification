{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, MaxPooling1D, Flatten, Embedding, Input\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorboard.plugins.pr_curve import summary as pr_summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../datasets/heli_uniform/heli_1m_uniform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(grid=False, figsize=(15,40), layout=(10,3), bins=100, sharex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is imbalanced with more positive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "(num_samples, num_features) = X.shape\n",
    "print (num_samples, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays Precision-Recall curve for Keras models.\n",
    "\n",
    "Adapted from: https://medium.com/@akionakas/precision-recall-curve-with-keras-cd92647685e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PRTensorBoard(TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # One extra argument to indicate whether or not to use the PR curve summary.\n",
    "        self.pr_curve = kwargs.pop('pr_curve', True)\n",
    "        super(PRTensorBoard, self).__init__(*args, **kwargs)\n",
    "\n",
    "        global tf\n",
    "        import tensorflow as tf\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super(PRTensorBoard, self).set_model(model)\n",
    "\n",
    "        if self.pr_curve:\n",
    "            # Get the prediction and label tensor placeholders.\n",
    "            predictions = self.model._feed_outputs[0]\n",
    "            labels = tf.cast(self.model._feed_targets[0], tf.bool)\n",
    "            # Create the PR summary OP.\n",
    "            self.pr_summary = pr_summary.op(name='pr_curve',\n",
    "                                            predictions=predictions,\n",
    "                                            labels=labels,\n",
    "                                            display_name='Precision-Recall Curve')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super(PRTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "        if self.pr_curve and self.validation_data:\n",
    "            # Get the tensors again.\n",
    "            tensors = self.model._feed_targets + self.model._feed_outputs\n",
    "            # Predict the output.\n",
    "            predictions = self.model.predict(self.validation_data[0])\n",
    "            # Build the dictionary mapping the tensor to the data.\n",
    "            val_data = [self.validation_data[1], predictions]\n",
    "            feed_dict = dict(zip(tensors, val_data))\n",
    "            # Run and add summary.\n",
    "            result = self.sess.run([self.pr_summary], feed_dict=feed_dict)\n",
    "            self.writer.add_summary(result[0], epoch)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(num_features,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print model.metrics_names\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "X_train_cnn = np.expand_dims(X_train.as_matrix(), axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test.as_matrix(), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 3x1 convolutions\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "conv1 = Conv1D(16, 3, padding='same', strides=1)(inputs)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "relu1 = Activation('relu')(bn1)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv2 = Conv1D(32, 3, padding='same', strides=1)(relu1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "relu2 = Activation('relu')(bn2)\n",
    "flatten = Flatten()(relu2)\n",
    "\n",
    "# FC 2048\n",
    "fc1 = Dense(2048)(flatten)\n",
    "bn3 = BatchNormalization()(fc1)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "drop1 = Dropout(0.5)(relu3)\n",
    "\n",
    "# FC 1024\n",
    "fc2 = Dense(1024)(drop1)\n",
    "bn4 = BatchNormalization()(fc2)\n",
    "relu4 = Activation('relu')(bn4)\n",
    "drop2 = Dropout(0.5)(relu4)\n",
    "\n",
    "# FC 512\n",
    "fc3 = Dense(512)(drop2)\n",
    "bn5 = BatchNormalization()(fc3)\n",
    "relu5 = Activation('relu')(bn5)\n",
    "drop3 = Dropout(0.5)(relu5)\n",
    "\n",
    "# Output\n",
    "fc4 = Dense(1)(drop3)\n",
    "outputs = Activation('sigmoid')(fc4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/10\n",
      "800000/800000 [==============================] - 2868s 4ms/step - loss: 0.2930 - acc: 0.8717 - val_loss: 0.1820 - val_acc: 0.9223\n",
      "Epoch 2/10\n",
      "800000/800000 [==============================] - 3693s 5ms/step - loss: 0.2261 - acc: 0.9029 - val_loss: 0.1575 - val_acc: 0.9355\n",
      "Epoch 3/10\n",
      "800000/800000 [==============================] - 2820s 4ms/step - loss: 0.2066 - acc: 0.9120 - val_loss: 0.1501 - val_acc: 0.9396\n",
      "Epoch 4/10\n",
      "800000/800000 [==============================] - 3235s 4ms/step - loss: 0.1942 - acc: 0.9177 - val_loss: 0.1279 - val_acc: 0.9488\n",
      "Epoch 5/10\n",
      "800000/800000 [==============================] - 3461s 4ms/step - loss: 0.1854 - acc: 0.9218 - val_loss: 0.1280 - val_acc: 0.9492\n",
      "Epoch 6/10\n",
      "800000/800000 [==============================] - 3518s 4ms/step - loss: 0.1788 - acc: 0.9247 - val_loss: 0.1238 - val_acc: 0.9505\n",
      "Epoch 7/10\n",
      "800000/800000 [==============================] - 3099s 4ms/step - loss: 0.1742 - acc: 0.9268 - val_loss: 0.1165 - val_acc: 0.9556\n",
      "Epoch 8/10\n",
      "800000/800000 [==============================] - 3064s 4ms/step - loss: 0.1706 - acc: 0.9287 - val_loss: 0.1160 - val_acc: 0.9545\n",
      "Epoch 9/10\n",
      "800000/800000 [==============================] - 3442s 4ms/step - loss: 0.1676 - acc: 0.9297 - val_loss: 0.1159 - val_acc: 0.9559\n",
      "Epoch 10/10\n",
      "800000/800000 [==============================] - 2753s 3ms/step - loss: 0.1650 - acc: 0.9313 - val_loss: 0.1116 - val_acc: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110eeab90>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_cnn, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[X_test_cnn, y_test], # NOTE: must pass test data for PRTensorBoard callback\n",
    "          shuffle=True,\n",
    "          callbacks=[PRTensorBoard(log_dir='logs/nadam_dropout50'), EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test_cnn, y_test, batch_size=batch_size)\n",
    "print model.metrics_names\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('models/cnn_16_32_dropout50_nadam.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
