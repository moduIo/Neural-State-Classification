{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, MaxPooling1D, Flatten, Embedding, Input\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorboard.plugins.pr_curve import summary as pr_summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs_data = ['neuron_params_d_I_samples_220K.csv', 'neuron_params_I_d_a_b_c_samples_110K.csv', 'neuron_params_I_d_a_b_samples_110K.csv', 'neuron_params_I_d_a_samples_110K.csv', 'neuron_params_I_samples_110K.csv']\n",
    "ys_data = ['neuron_params_d_I_labels_220K.csv', 'neuron_params_I_d_a_b_c_labels_110K.csv', 'neuron_params_I_d_a_b_labels_110K.csv', 'neuron_params_I_d_a_labels_110K.csv', 'neuron_params_I_labels_110K.csv']\n",
    "Xs = []\n",
    "ys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in Xs_data:\n",
    "    Xs.append(pd.read_csv('../../datasets/parametric_neuron_data/' + path, index_col=0, header=None).T)\n",
    "    \n",
    "for path in ys_data:\n",
    "    ys.append(pd.read_csv('../../datasets/parametric_neuron_data/' + path, index_col=0, header=None).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"header\" as data\n",
    "for X in Xs:\n",
    "    X.loc[-1] = X.columns\n",
    "    \n",
    "for y in ys:\n",
    "    y.loc[-1] = y.columns\n",
    "    \n",
    "# Select dataset\n",
    "dataset = 1\n",
    "X = Xs[dataset]\n",
    "y = ys[dataset]\n",
    "(num_samples, num_features) = X.shape\n",
    "\n",
    "# Normalize input\n",
    "X = X.apply(zscore)\n",
    "\n",
    "# 80/20 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "# Add an extra dimension to  XX  for 1-D convolution.\n",
    "X_train_cnn = np.expand_dims(X_train.as_matrix(), axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test.as_matrix(), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays Precision-Recall curve for Keras models.\n",
    "\n",
    "Adapted from: https://medium.com/@akionakas/precision-recall-curve-with-keras-cd92647685e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PRTensorBoard(TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # One extra argument to indicate whether or not to use the PR curve summary.\n",
    "        self.pr_curve = kwargs.pop('pr_curve', True)\n",
    "        super(PRTensorBoard, self).__init__(*args, **kwargs)\n",
    "\n",
    "        global tf\n",
    "        import tensorflow as tf\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super(PRTensorBoard, self).set_model(model)\n",
    "\n",
    "        if self.pr_curve:\n",
    "            # Get the prediction and label tensor placeholders.\n",
    "            predictions = self.model._feed_outputs[0]\n",
    "            labels = tf.cast(self.model._feed_targets[0], tf.bool)\n",
    "            # Create the PR summary OP.\n",
    "            self.pr_summary = pr_summary.op(name='pr_curve',\n",
    "                                            predictions=predictions,\n",
    "                                            labels=labels,\n",
    "                                            display_name='Precision-Recall Curve')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super(PRTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "        if self.pr_curve and self.validation_data:\n",
    "            # Get the tensors again.\n",
    "            tensors = self.model._feed_targets + self.model._feed_outputs\n",
    "            # Predict the output.\n",
    "            predictions = self.model.predict(self.validation_data[0])\n",
    "            # Build the dictionary mapping the tensor to the data.\n",
    "            val_data = [self.validation_data[1], predictions]\n",
    "            feed_dict = dict(zip(tensors, val_data))\n",
    "            # Run and add summary.\n",
    "            result = self.sess.run([self.pr_summary], feed_dict=feed_dict)\n",
    "            self.writer.add_summary(result[0], epoch)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 3x1 convolutions\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "conv1 = Conv1D(4, 3, padding='same', strides=1)(inputs)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "relu1 = Activation('relu')(bn1)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv2 = Conv1D(8, 3, padding='same', strides=1)(relu1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "relu2 = Activation('relu')(bn2)\n",
    "flatten = Flatten()(relu2)\n",
    "\n",
    "# FC 2048\n",
    "fc1 = Dense(32)(flatten)\n",
    "bn3 = BatchNormalization()(fc1)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "\n",
    "# FC 1024\n",
    "fc2 = Dense(16)(relu3)\n",
    "bn4 = BatchNormalization()(fc2)\n",
    "relu4 = Activation('relu')(bn4)\n",
    "\n",
    "# FC 512\n",
    "fc3 = Dense(16)(relu4)\n",
    "bn5 = BatchNormalization()(fc3)\n",
    "relu5 = Activation('relu')(bn5)\n",
    "\n",
    "# Output\n",
    "fc4 = Dense(1)(relu5)\n",
    "outputs = Activation('sigmoid')(fc4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176000 samples, validate on 44000 samples\n",
      "Epoch 1/10\n",
      "176000/176000 [==============================] - 53s 302us/step - loss: 0.0380 - acc: 0.9839 - val_loss: 0.0335 - val_acc: 0.9865\n",
      "Epoch 2/10\n",
      "176000/176000 [==============================] - 39s 223us/step - loss: 0.0384 - acc: 0.9837 - val_loss: 0.0336 - val_acc: 0.9862\n",
      "Epoch 3/10\n",
      "176000/176000 [==============================] - 39s 223us/step - loss: 0.0380 - acc: 0.9839 - val_loss: 0.0339 - val_acc: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e805910>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_cnn, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[X_test_cnn, y_test], # NOTE: must pass test data for PRTensorBoard callback\n",
    "          shuffle=True,\n",
    "          callbacks=[PRTensorBoard(log_dir='logs/adam_dropout-50_dataset-' + str(dataset)), EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "###BEST 0.9721\n",
    "# 16 3x1 convolutions\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "conv1 = Conv1D(16, 3, padding='same', strides=1)(inputs)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "relu1 = Activation('relu')(bn1)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv2 = Conv1D(32, 3, padding='same', strides=1)(relu1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "relu2 = Activation('relu')(bn2)\n",
    "flatten = Flatten()(relu2)\n",
    "\n",
    "# FC 2048\n",
    "fc1 = Dense(256)(flatten)\n",
    "bn3 = BatchNormalization()(fc1)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "drop1 = Dropout(0.5)(relu3)\n",
    "\n",
    "# FC 1024\n",
    "fc2 = Dense(128)(drop1)\n",
    "bn4 = BatchNormalization()(fc2)\n",
    "relu4 = Activation('relu')(bn4)\n",
    "drop2 = Dropout(0.5)(relu4)\n",
    "\n",
    "# FC 512\n",
    "fc3 = Dense(64)(drop2)\n",
    "bn5 = BatchNormalization()(fc3)\n",
    "relu5 = Activation('relu')(bn5)\n",
    "drop3 = Dropout(0.5)(relu5)\n",
    "\n",
    "# Output\n",
    "fc4 = Dense(1)(drop3)\n",
    "outputs = Activation('sigmoid')(fc4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "opt = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## TEST\n",
    "##\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "conv1 = Conv1D(16, 3, padding='same', strides=1)(inputs)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "relu1 = Activation('relu')(bn1)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv2 = Conv1D(32, 3, padding='same', strides=1)(relu1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "relu2 = Activation('relu')(bn2)\n",
    "flatten = Flatten()(relu2)\n",
    "\n",
    "# FC 2048\n",
    "fc1 = Dense(128)(flatten)\n",
    "bn3 = BatchNormalization()(fc1)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "drop1 = Dropout(0.5)(relu3)\n",
    "\n",
    "# FC 1024\n",
    "fc2 = Dense(64)(drop1)\n",
    "bn4 = BatchNormalization()(fc2)\n",
    "relu4 = Activation('relu')(bn4)\n",
    "drop2 = Dropout(0.5)(relu4)\n",
    "\n",
    "# FC 512\n",
    "fc3 = Dense(32)(drop2)\n",
    "bn5 = BatchNormalization()(fc3)\n",
    "relu5 = Activation('relu')(bn5)\n",
    "drop3 = Dropout(0.5)(relu5)\n",
    "\n",
    "# Output\n",
    "fc4 = Dense(1)(drop3)\n",
    "outputs = Activation('sigmoid')(fc4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Nadam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88000 samples, validate on 22000 samples\n",
      "Epoch 1/10\n",
      "88000/88000 [==============================] - 30s 346us/step - loss: 0.1248 - acc: 0.9525 - val_loss: 0.0874 - val_acc: 0.9647\n",
      "Epoch 2/10\n",
      "88000/88000 [==============================] - 30s 335us/step - loss: 0.1163 - acc: 0.9561 - val_loss: 0.0866 - val_acc: 0.9654\n",
      "Epoch 3/10\n",
      "88000/88000 [==============================] - 25s 286us/step - loss: 0.1094 - acc: 0.9591 - val_loss: 0.0829 - val_acc: 0.9674\n",
      "Epoch 4/10\n",
      "88000/88000 [==============================] - 25s 285us/step - loss: 0.1105 - acc: 0.9587 - val_loss: 0.0793 - val_acc: 0.9695\n",
      "Epoch 5/10\n",
      "88000/88000 [==============================] - 25s 286us/step - loss: 0.1063 - acc: 0.9604 - val_loss: 0.0804 - val_acc: 0.9685\n",
      "Epoch 6/10\n",
      "88000/88000 [==============================] - 26s 298us/step - loss: 0.1039 - acc: 0.9606 - val_loss: 0.0782 - val_acc: 0.9705\n",
      "Epoch 7/10\n",
      "88000/88000 [==============================] - 25s 288us/step - loss: 0.1022 - acc: 0.9614 - val_loss: 0.0762 - val_acc: 0.9698\n",
      "Epoch 8/10\n",
      "88000/88000 [==============================] - 25s 286us/step - loss: 0.1012 - acc: 0.9619 - val_loss: 0.0740 - val_acc: 0.9716\n",
      "Epoch 9/10\n",
      "88000/88000 [==============================] - 25s 287us/step - loss: 0.0986 - acc: 0.9624 - val_loss: 0.0788 - val_acc: 0.9703\n",
      "Epoch 10/10\n",
      "88000/88000 [==============================] - 28s 313us/step - loss: 0.1001 - acc: 0.9615 - val_loss: 0.0805 - val_acc: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e900290>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_cnn, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[X_test_cnn, y_test], # NOTE: must pass test data for PRTensorBoard callback\n",
    "          shuffle=True,\n",
    "          callbacks=[PRTensorBoard(log_dir='logs/nadam_dropout-50_dataset-' + str(dataset)), EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [0.98625, 0.9721, 0, 0, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
