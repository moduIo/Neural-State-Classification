{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, MaxPooling1D, Flatten, Embedding, Input\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorboard.plugins.pr_curve import summary as pr_summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs_data = ['neuron_params_d_I_samples_220K.csv', 'neuron_params_I_d_a_b_c_samples_110K.csv', 'neuron_params_I_d_a_b_samples_110K.csv', 'neuron_params_I_d_a_samples_110K.csv', 'neuron_params_I_samples_110K.csv']\n",
    "ys_data = ['neuron_params_d_I_labels_220K.csv', 'neuron_params_I_d_a_b_c_labels_110K.csv', 'neuron_params_I_d_a_b_labels_110K.csv', 'neuron_params_I_d_a_labels_110K.csv', 'neuron_params_I_labels_110K.csv']\n",
    "Xs = []\n",
    "ys = []\n",
    "results = [None, None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in Xs_data:\n",
    "    Xs.append(pd.read_csv('../../datasets/parametric_neuron_data/' + path, index_col=0, header=None).T)\n",
    "    \n",
    "for path in ys_data:\n",
    "    ys.append(pd.read_csv('../../datasets/parametric_neuron_data/' + path, index_col=0, header=None).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"header\" as data\n",
    "for X in Xs:\n",
    "    X.loc[-1] = X.columns\n",
    "    \n",
    "for y in ys:\n",
    "    y.loc[-1] = y.columns\n",
    "    \n",
    "# Select dataset\n",
    "dataset = 0\n",
    "X = Xs[dataset]\n",
    "y = ys[dataset]\n",
    "(num_samples, num_features) = X.shape\n",
    "\n",
    "# Normalize input\n",
    "X = X.apply(zscore)\n",
    "\n",
    "# 80/20 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "# Add an extra dimension to  XX  for 1-D convolution.\n",
    "X_train_cnn = np.expand_dims(X_train.as_matrix(), axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test.as_matrix(), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays Precision-Recall curve for Keras models.\n",
    "\n",
    "Adapted from: https://medium.com/@akionakas/precision-recall-curve-with-keras-cd92647685e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PRTensorBoard(TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # One extra argument to indicate whether or not to use the PR curve summary.\n",
    "        self.pr_curve = kwargs.pop('pr_curve', True)\n",
    "        super(PRTensorBoard, self).__init__(*args, **kwargs)\n",
    "\n",
    "        global tf\n",
    "        import tensorflow as tf\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super(PRTensorBoard, self).set_model(model)\n",
    "\n",
    "        if self.pr_curve:\n",
    "            # Get the prediction and label tensor placeholders.\n",
    "            predictions = self.model._feed_outputs[0]\n",
    "            labels = tf.cast(self.model._feed_targets[0], tf.bool)\n",
    "            # Create the PR summary OP.\n",
    "            self.pr_summary = pr_summary.op(name='pr_curve',\n",
    "                                            predictions=predictions,\n",
    "                                            labels=labels,\n",
    "                                            display_name='Precision-Recall Curve')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super(PRTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "        if self.pr_curve and self.validation_data:\n",
    "            # Get the tensors again.\n",
    "            tensors = self.model._feed_targets + self.model._feed_outputs\n",
    "            # Predict the output.\n",
    "            predictions = self.model.predict(self.validation_data[0])\n",
    "            # Build the dictionary mapping the tensor to the data.\n",
    "            val_data = [self.validation_data[1], predictions]\n",
    "            feed_dict = dict(zip(tensors, val_data))\n",
    "            # Run and add summary.\n",
    "            result = self.sess.run([self.pr_summary], feed_dict=feed_dict)\n",
    "            self.writer.add_summary(result[0], epoch)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 3x1 convolutions\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "conv1 = Conv1D(32, 5, padding='same', strides=1)(inputs)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "relu1 = Activation('relu')(bn1)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv2 = Conv1D(64, 3, padding='same', strides=1)(relu1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "relu2 = Activation('relu')(bn2)\n",
    "flatten = Flatten()(relu2)\n",
    "\n",
    "# FC 2048\n",
    "fc1 = Dense(1024)(flatten)\n",
    "bn3 = BatchNormalization()(fc1)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "drop1 = Dropout(0.5)(relu3)\n",
    "\n",
    "# FC 1024\n",
    "fc2 = Dense(512)(drop1)\n",
    "bn4 = BatchNormalization()(fc2)\n",
    "relu4 = Activation('relu')(bn4)\n",
    "drop2 = Dropout(0.5)(relu4)\n",
    "\n",
    "# FC 512\n",
    "fc3 = Dense(256)(drop2)\n",
    "bn5 = BatchNormalization()(fc3)\n",
    "relu5 = Activation('relu')(bn5)\n",
    "drop3 = Dropout(0.5)(relu5)\n",
    "\n",
    "# Output\n",
    "fc4 = Dense(1)(drop3)\n",
    "outputs = Activation('sigmoid')(fc4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176000 samples, validate on 44000 samples\n",
      "Epoch 1/10\n",
      " 65952/176000 [==========>...................] - ETA: 1:48 - loss: 0.0960 - acc: 0.9606"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_cnn, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[X_test_cnn, y_test], # NOTE: must pass test data for PRTensorBoard callback\n",
    "          shuffle=True,\n",
    "          callbacks=[PRTensorBoard(log_dir='logs/nadam_dropout-50_dataset-' + str(dataset)), EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tim/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "# 16 3x1 convolutions\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "conv1 = Conv1D(32, 5, padding='same', strides=1)(inputs)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "relu1 = Activation('relu')(bn1)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv2 = Conv1D(64, 3, padding='same', strides=1)(relu1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "relu2 = Activation('relu')(bn2)\n",
    "\n",
    "# 32 3x16 convolutions\n",
    "conv3 = Conv1D(32, 3, padding='same', strides=1)(relu2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "flatten = Flatten()(relu3)\n",
    "\n",
    "# FC 2048\n",
    "fc1 = Dense(1024)(flatten)\n",
    "bn3 = BatchNormalization()(fc1)\n",
    "relu3 = Activation('relu')(bn3)\n",
    "drop1 = Dropout(0.5)(relu3)\n",
    "\n",
    "# FC 1024\n",
    "fc2 = Dense(512)(drop1)\n",
    "bn4 = BatchNormalization()(fc2)\n",
    "relu4 = Activation('relu')(bn4)\n",
    "drop2 = Dropout(0.5)(relu4)\n",
    "\n",
    "# FC 512\n",
    "fc3 = Dense(256)(drop2)\n",
    "bn5 = BatchNormalization()(fc3)\n",
    "relu5 = Activation('relu')(bn5)\n",
    "drop3 = Dropout(0.5)(relu5)\n",
    "\n",
    "# Output\n",
    "fc4 = Dense(1)(drop3)\n",
    "outputs = Activation('sigmoid')(fc4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_cnn, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[X_test_cnn, y_test], # NOTE: must pass test data for PRTensorBoard callback\n",
    "          shuffle=True,\n",
    "          callbacks=[PRTensorBoard(log_dir='logs/nadam_dropout-50_dataset-' + str(dataset)), EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test_cnn, y_test, batch_size=batch_size)\n",
    "print model.metrics_names\n",
    "print score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
